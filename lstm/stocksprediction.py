# -*- coding: utf-8 -*-
"""StocksPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-mz-9-yIpYGsauK57C7pgadww64kG6gF
"""

#Import Libaries - Data 
import math
import numpy as np

from sklearn.preprocessing import MinMaxScaler

from keras.models import Sequential
from keras.layers import Dense, LSTM

import pandas as pd
import pandas_datareader as reader

import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

#Target company
target_company = 'AAPL'
predictor_companies = ['MSFT', 'AMD', 'INTC']

#Get previous target stock quotes
tc = reader.DataReader(target_company, data_source='yahoo', start='2020-01-01')
#show data
tc

#Get previous stock quotes for predictor companies
pred_quotes = reader.DataReader(predictor_companies, data_source='yahoo', start='2020-01-01')
pred_quotes['Close']

tc.shape

#Visualize the closing price history for company data
plt.figure(figsize=(16, 8))
plt.title('Close Price History')
plt.plot(tc['Close'])
plt.plot(pred_quotes['Close'])
plt.legend()
plt.xlabel('Data', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.show

#Create new data frames from only the Close column
data_target = tc.filter(['Close'])
data_pred = pred_quotes['Close']

#Convert the data frames to an array
dataset_target = data_target.values
dataset_pred = data_pred.values

#Convert the number of rows to train the model on
training_target_data_len = math.ceil(len(dataset_target) * .8)
training_pred_data_len = math.ceil(len(dataset_pred) * .8)

if (training_target_data_len != training_pred_data_len):
  raise Exception('Data set build error')

training_data_len = training_pred_data_len
training_data_len

#Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_target_data = scaler.fit_transform(dataset_target)
scaled_pred_data = scaler.fit_transform(dataset_pred)
# print(f'{scaled_pred_data}\n{scaled_target_data}')

#Create the training data set
#Create the scaled training data set
train_target_data = scaled_target_data[0:training_data_len, :]
train_pred_data = scaled_pred_data[0:training_data_len, :]
x_train = []
y_train = []

for i in range (60, len(train_target_data)):
  x_train.append(train_data)

