# -*- coding: utf-8 -*-
"""StocksPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-mz-9-yIpYGsauK57C7pgadww64kG6gF
"""

#Import Libaries - Data 
import math
import numpy as np

from sklearn.preprocessing import MinMaxScaler

from keras.models import Sequential
from keras.layers import Dense, LSTM

import pandas as pd
import pandas_datareader as reader

import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

#List of Companies to be analyzed
companies = ['AAPL','MSFT', 'AMD', 'INTC']
#Target company index
target = 0
#Sets the number of days the LSTM will use in the prediction
sample_size = 60

target_quotes = reader.DataReader(companies[target], data_source='yahoo', start='2011-01-01')
target_quotes

#Get previous stock quotes for predictor companies
quotes = reader.DataReader(companies, data_source='yahoo', start='2011-01-01')
quotes['Close']

#Create new data frames from only the Close column
data = quotes.Close

#Convert the data frames to an array
dataset = data.values

#Convert the number of rows to train the model on
training_data_len = math.ceil(len(dataset) * .8)
training_data_len

#Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#Create the training data set
#Create the scaled training data set
train_data = scaled_data[0:training_data_len, :]

#Change the train data into a numpy array
train_data = np.array(train_data)
#Transpose the train data array
train_data = train_data.T
train_data[0]

#Creating the testing dataset
test_data = scaled_data[training_data_len - 60: , : ]
test_data.shape

#Create a numpy array of x train data 
#LSTM expects the input to be 3 dimensional in the form num of samples, num of timesteps, num of features
x_train = 0
x_train_flag = 0
for comp in range(train_data.shape[0]):
  x_train_layer = []
  for i in range(sample_size, train_data.shape[1]):
    x_train_layer.append(train_data[comp][i - 60: i]);
  x_train_layer = np.array(x_train_layer)
  if (x_train_flag == 0):
    x_train = x_train_layer
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
    x_train_flag = 1
  else:
    x_train_layer = np.reshape(x_train_layer, (x_train_layer.shape[0], x_train_layer.shape[1], 1))
    x_train = np.concatenate((x_train, x_train_layer), axis=2)

#Create a list of y training values
y_train = []
for i in range(60, train_data.shape[1]):
  y_train.append(train_data[target][i])

#Convert y_train into a numpy array
y_train = np.array(y_train)

#Building the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

#Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

#Train the model
model.fit(x_train, y_train, batch_size=1, epochs=1)

#Create the dataset for testing 
test_data = scaled_data[training_data_len - 60: , :]
test_data = test_data.T


#Create the data set for x_test
x_test = 0
x_test_flag = 0
for comp in range(test_data.shape[0]):
  x_test_layer = []
  for i in range(sample_size, test_data.shape[1]):
    x_test_layer.append(test_data[comp][i - 60: i]);
  x_test_layer = np.array(x_test_layer)
  if (x_test_flag == 0):
    x_test = x_test_layer
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test_flag = 1
  else:
    x_test_layer = np.reshape(x_test_layer, (x_test_layer.shape[0], x_test_layer.shape[1], 1))
    x_test = np.concatenate((x_test, x_test_layer), axis=2)
  
x_test.shape

#Create the data set for y_test
y_test = dataset[training_data_len:, :]
y_test

#Get the models predicted price values
predictions = model.predict(x_test)
#The scaler expects the array to be a multidimensional array
predictions = np.concatenate((predictions, predictions), axis=1)
predictions = np.concatenate((predictions, predictions), axis=1)
#Remove the scalling on the model
predictions = scaler.inverse_transform(predictions)
predictions = predictions.T[0].T
predictions = np.reshape(predictions, (predictions.shape[0], 1))
predictions.shape

#Get the root mean square error (RMSE)
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))
rmse

import csv

def csvEditor(fileName, data, type):
    with open(f'{fileName}', f'{type}', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(data)

csvEditor("data/lstmOutput.csv", predictions.T[0], 'w')





